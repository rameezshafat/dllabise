{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fa61d168-68af-473a-b7b7-023d761409ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics import Accuracy\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5c06fe50-1bd9-43ee-8e86-d8b4541bdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 12\n",
    "LR = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0e143341-4c54-4d7b-9709-ecb1ac5fb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root=\"./dataprogram6/\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./dataprogram6/\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f7a0de4f-9c71-4062-b415-deb7c1f0938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), nn.Tanh(), nn.AvgPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5), nn.Tanh(), nn.AvgPool2d(2, 2)\n",
    "        )\n",
    "        self.flattened_size = self._get_flattened_size()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flattened_size, 120), nn.Tanh(),\n",
    "            nn.Linear(120, 84), nn.Tanh(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 1, 28, 28)\n",
    "            return self.feature_extractor(dummy_input).numel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2c2b355a-df99-4aa4-90cb-6c5cf7c74b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "23166024-8a73-4b9d-a551-ed62ab3f5117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aad9ae4b8744b4a94251d73079895b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12 | Train Loss: 0.05125 | Train Acc: 0.98384 | Val Loss: 0.05921 | Val Acc: 0.98138\n",
      "Epoch 2/12 | Train Loss: 0.04013 | Train Acc: 0.98774 | Val Loss: 0.04813 | Val Acc: 0.98521\n",
      "Epoch 3/12 | Train Loss: 0.03335 | Train Acc: 0.98937 | Val Loss: 0.04702 | Val Acc: 0.98537\n",
      "Epoch 4/12 | Train Loss: 0.02754 | Train Acc: 0.99119 | Val Loss: 0.04780 | Val Acc: 0.98321\n",
      "Epoch 5/12 | Train Loss: 0.02435 | Train Acc: 0.99200 | Val Loss: 0.05517 | Val Acc: 0.98288\n",
      "Epoch 6/12 | Train Loss: 0.02005 | Train Acc: 0.99339 | Val Loss: 0.03944 | Val Acc: 0.98870\n",
      "Epoch 7/12 | Train Loss: 0.01766 | Train Acc: 0.99424 | Val Loss: 0.04398 | Val Acc: 0.98820\n",
      "Epoch 8/12 | Train Loss: 0.01714 | Train Acc: 0.99437 | Val Loss: 0.05091 | Val Acc: 0.98620\n",
      "Epoch 9/12 | Train Loss: 0.01408 | Train Acc: 0.99522 | Val Loss: 0.05121 | Val Acc: 0.98920\n",
      "Epoch 10/12 | Train Loss: 0.01279 | Train Acc: 0.99563 | Val Loss: 0.05171 | Val Acc: 0.98737\n",
      "Epoch 11/12 | Train Loss: 0.01241 | Train Acc: 0.99587 | Val Loss: 0.05300 | Val Acc: 0.98637\n",
      "Epoch 12/12 | Train Loss: 0.01058 | Train Acc: 0.99678 | Val Loss: 0.05747 | Val Acc: 0.98720\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    ###### Training Loop ######\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    \n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)  # Forward pass\n",
    "        loss = loss_fn(y_pred, y)  # Compute loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(y_pred.argmax(dim=1), y).item()  # Convert accuracy to scalar\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    ###### Validation Loop ######\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():  # Use torch.no_grad() to avoid inplace update errors\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_acc += accuracy(y_pred.argmax(dim=1), y).item()  # Convert accuracy to scalar\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc /= len(val_loader)\n",
    "\n",
    "    \n",
    "\n",
    "    ###### Print Progress ######\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.5f} | Val Loss: {val_loss:.5f} | Val Acc: {val_acc:.5f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39caccd3-fa52-438c-8293-f03641cdee84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
